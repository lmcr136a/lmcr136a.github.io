<!DOCTYPE html>

<head>
    <title>Nahyeon Kim</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" href="./css/index.css">

    <script src="https://kit.fontawesome.com/8c9171bec9.js" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://unpkg.com/tippy.js@6/animations/scale.css" />
    <link rel="stylesheet" href="https://unpkg.com/tippy.js@6/animations/scale.css" />
    <link rel="icon" href="/assets/Portfolio Icon.jfif">
</head>


<body>
    <!-- GRADIANT EFFECT ON TOP -->
<!--    <h1 id="main-heading" class="gradiant-effect"></h1>-->
    <!-- MAIN DIVIDER WHICH CONTAINS ALL THE OTHER CATEGORY-->
    <div id="main-box" style=" width: 1034px;">
        <!-- ABOUT ME SECTION -->
        <div class="d-flex justify-content-center container-xxl" id="about-me">
            <div class="d-flex">
                <div class="flex-shrink-1">
                    <picture> 
                        <img id="profile-pic" src="/assets/MyPhoto.jpg" alt="NahyeonKim.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> 
                    </picture> 
                    <!-- <img src="assets/MyPhoto.jpg" alt="image"> -->
                     
                    <br><br><br><br>
                    <div class="row">
                        <!-- <div class="col-4 text-center"><iframe src="assets/CV_Kim.pdf" width="600" height="400">CV</iframe></div> -->
                        <div class="col-4 text-center"><a href="mailto:lmcr136a@g.ucla.edu"><i class="fa-regular fa-envelope fa-2xl" data-tippy-content="E-Mail"></i></a></div>
                        <div class="col-4 text-center"><a href="https://www.linkedin.com/in/steamhyeon/"><i class="fa-brands fa-linkedin fa-2xl" data-tippy-content="LinkedIn"></i></a></div>
                        <div class="col-4 text-center"><a href="https://github.com/lmcr136a?tab=repositories"><i class="fa-brands fa-github fa-2xl" data-tippy-content="GitHub"></i></a></div>
                    </div>
                </div>
                <div class="flex-grow-1 ms-5 name-heading">
                    <!-- NAME OF THE PERSON -->
                    <h1>(Evelyn) Nahyeon Kim</h1>
                    <!-- ABOUT HIM -->
                    <p style="text-align: justify">
                        Hi &#128516;
                        <br>
                        <br>
                        I am an AI researcher at <a href="https://connecteve.com/">CONNECTEVE Inc.</a>, studying <strong>diffusion models</strong> for medical treatments. 
                        I earned my master's degree at UCLA in 2024, where I conducted research on <strong>Neural Radiance Fields (NeRF)</strong> 
                        under the supervision of <a href="https://samueli.ucla.edu/people/m-khalid-jawed/">Prof. M. Khalid Jawed</a> at the <a href="https://structures.computer/">Structures-Computer Interaction Lab</a>.
                        I received my Bachelor's Degree in Mechanical Engineering from <a href="https://en.snu.ac.kr/index.html">Seoul National University</a>, Korea, in 2023. 
                        <br>
                        <br>
                        During my undergraduate studies, I participated in various research projects.
                        I worked on <strong>Optical Character Recognition (OCR)</strong> at SaigeResearch Inc. 
                        and explored <strong>Knowledge Distillation</strong> and <strong>Neural Network Inversion</strong> at 
                        the <a href="https://www.kist.re.kr/eng/index.do">Korea Institute of Science and Technology (KIST)</a> from 2021 to 2022.
                        In 2023, I focused on developing a <strong>Visual Position System (VPS)</strong>
                        to map users to VR world coordinates while working as a research engineer at VR Crew Inc.
                        <br>
                        <br>
                        I am passionate about advancing AI research by integrating knowledge from diverse fields to create innovative solutions. 
                        My primary research interest lies in researching diverse applications 
                        utilizing cutting-edge machine learning technologies, particularly in computer vision.
                        My research goal is to gain expertise in creating AI systems that achieve the perfect synergy of various domains. 
                        I am always open to productive discussions about research, so please donâ€™t hesitate to reach out!
                    </p>
                    <br>
                </div>
            </div>
        </div>
        <!-- <br> -->

        <div style=" width: 1034px;">
            <h1 id="cv"><a href="assets/CV_Kim.pdf" target="_blank">[ Curriculum Vitae3 ]</a></h1>
        </div>

        <div class="container-xxl heading" style=" width: 1034px;">
            <h1>PROJECTS</h1>
        </div>
        <br>
        <!-- PROJECT THAT HE OWNS -->
        <div class="container-xxl" style="width: 1034px;" id="projects">
            <div class="row row-cols-1 g-4">

                <!-- <div class="col">
                    <div class="card project-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <img src="assets/DINER_teaser.jpg" class="img-fluid">
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">DINER: Depth-aware Image-based NEural Radiance fields</h5>
                              <a href="projects/diner/diner.html" class="stretched-link hidden"></a>
                            <p class="project-card-text">We present Depth-aware Image-based NEural Radiance fields (DINER). Given a sparse set of RGB input views, we predict depth and feature maps to guide the reconstruction of a volumetric scene representation that allows us to render 3D objects under novel views. Specifically, we propose novel techniques to incorporate depth information into feature fusion and efficient scene sampling. In comparison to the previous state of the art, DINER achieves higher synthesis quality and can process input views with greater disparity. This allows us to capture scenes more completely without changing capturing hardware requirements and ultimately enables larger viewpoint changes during novel view synthesis. We evaluate our method by synthesizing novel views, both for human heads and for general objects, and observe significantly improved qualitative results and increased perceptual metrics compared to the previous state of the art. The code will be made publicly available for research purposes.</p>
                            <br>
                          </div>
                        </div>
                      </div>
                    </div>
                </div> -->
                <div class="col">
                    <div class="card project-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <img src="assets/Asim.png" class="img-fluid">
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Neural Radiance Fields (NeRF) with Reinforcement Learning</h5>
                              <a href="https://github.com/lmcr136a/AgriSim-virtual-NeRF-training" class="stretched-link hidden"></a>
                            <p class="project-card-text">
                                In this project, we implement a pipeline that uses reinforcement learning to find the optimal image positions necessary for training the NeRF model. The pipeline begins with the AgriSim module, a Python library that generates a NeRF of a ShapeNet 3D object using the Unity Game Engine and Instant-NGP. It starts with a basic Unity environment, where a 3D mesh object is simulated within the Unity framework. AgriSim's unity_sampler captures images of the target object within the Unity environment and saves these images with transforms.json, which contains translation, rotation, and the physical characteristics of the camera.
                                Using this dataset, the reinforcement learning agent within the AgriSim-RL module seeks to find the most effective positions of images for the training of the NeRF model. At each step, the agent predicts the camera position coordinates, and trains the NeRF model using images captured from these coordinates. After training, the agent's reward is assessed using validation metrics of the model, and the agent aims to increase the validation performance of the NeRF model.

                            </p>
                            <br>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card project-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <img src="assets/KDO.png" class="img-fluid">
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Data-Free Retraining of Pruned Networks</h5>
                              <a href="https://github.com/lmcr136a/mod" class="stretched-link hidden"></a>
                            <p class="project-card-text">
                                Owing to concerns about privacy and licensing, there is an increasing trend of releasing large models without providing access to the training data. 
                                This makes network pruning less efficient since retraining after pruning necessitates training data. 
                                To work around the absence of the original training data, data-free pruning resorts to network inversion data generated from the model. 
                                However, since the distribution of this synthetic data differs significantly from the original, fine-tuning with synthetic data leads to limited performance improvement or even a decrease in some cases. 
                                To overcome this problem, we propose KD-only (KDO), a knowledge distillation method with only Kullback-Leibler divergence loss, as a better alternative to fine-tuning. 
                                The key intuition is that we do not trust the fidelity of the synthetic data; we use these data as the input points at which the pruned model is trained to follow the behavior of the original model. 
                                Our experiments with data-free pruning of various models demonstrate that KDO consistently outperforms fine-tuning. 
                                The effectiveness of our method remains robust even with a limited number of images or lower image quality,  thereby enhancing the applicability of data-free pruning. 
                            </p>
                            <br>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card project-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <img src="assets/comvi.png" class="img-fluid">
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Comparative Analysis: Traditional Computer Vision and Deep Learning</h5>
                              <a href="https://github.com/lmcr136a/comvi" class="stretched-link hidden"></a>
                            <p class="project-card-text">
                                The advent of deep learning has yielded remarkable results across various computer vision tasks. In a bid to enhance performance, several traditional computer vision techniques have been integrated into deep learning frameworks. This repository presents a comparative study examining the performance of deep neural networks when augmented with traditional computer vision algorithms: Warping, SIFT, Edge Detection, and Gabor Filters.
                                We utilized ResNet18 and modified the first convolutional layer to adjust the number of input image channels. Our experimentation involved CIFAR10, CIFAR100, as well as high-resolution datasets such as the Oxford 102 Flower Dataset and the Large Scale Fish Dataset, aiming to enhance the performance and impact of computer vision tasks.

                            </p>
                            <br>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card project-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <img src="assets/opengl.png" class="img-fluid">
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Spline Visualization and Scene Rendering with OpenGL</h5>
                              <a href="https://github.com/lmcr136a/Graphics_OpenGL?tab=readme-ov-file" class="stretched-link hidden"></a>
                            <p class="project-card-text">
                                This is an OpenGL project that includes creating scenes including Implicit Surfaces and Polygonal Objects, allowing dynamic rendering and interaction with the user. Users can manipulate the camera and change scenes using mouse and keyboard controls within the visualization window. The project extends to ray tracing scenes containing objects with various materials represented by the Phong illumination model.

To create polygonal objects, B-Spline and Catmull-Rom spline methods are used with coordinates of control points, which are parsed from the data file.
It utilizes a total of 4 light sources and employs recursive reflection to represent light reflection.
                            </p>
                            <br>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

            </div>
        </div>

        <br>
        <br>

        <div class="container-xxl heading" style=" width: 1034px;">
            <h1>EXPERIENCE & EDUCATION</h1>
        </div>
        <br>
        <div class="container-xxl" style="width: 1034px;">
            <div class="row row-cols-1 g-4">
                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 200px">
                                <a href="https://structures.computer/"><img src="assets/connecteve.jpg" class="img-fluid" style="width: 75%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Research Engineer</h5>
                              <p class="card-text"><small class="text-muted">CONNECTEVE.Inc &nbsp; &nbsp; &nbsp;  &nbsp;&nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                                Since Aug 2024</small></p>
                            <p class="card-text">Supervised by <a href="https://snucm.elsevierpure.com/en/persons/y-ro">Dr. (Prof.) Duhyun Ro</a>, 
                                researched difussion models for medical treatments.</p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 200px">
                                <a href="https://structures.computer/"><img src="assets/sci_lab.png" class="img-fluid" style="width: 75%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">M.S. Student</h5>
                              <p class="card-text"><small class="text-muted">Structures-Computer Interaction Lab &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                                Sep 2023 - Jun 2024</small></p>
                            <p class="card-text">Supervised by <a href="https://samueli.ucla.edu/people/m-khalid-jawed/">Dr. (Prof.) M. Khalid Jawed</a>, 
                                my research focuses on Neural Radiance Fields (NeRF) and self-supervised learning.</p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 224px">
                                <a href="https://www.linkedin.com/company/vrcrewinc/?originalSubdomain=kr"><img src="assets/vrcrew_logo.jpg" class="img-fluid" style="width: 60%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Research Engineer</h5>
                            <p class="card-text"><small class="text-muted">VR Crew Inc. &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                              Jan 2023 - Aug 2023</small></p>
                              Developed a framework at the core of the company's Vision Positioning System, integrating point cloud analysis, computer vision deep learning, and epipolar geometry. 
                              Led research focused on Keypoint Extractor, PnP, PnL, Point Matching, and Global Descriptor. 
                              <p class="card-text">

                              </p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>

                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 224px">
                                <a href="https://www.kist.re.kr/eng/index.do"><img src="assets/KIST_Logo.jpg" class="img-fluid" style="width: 60%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">AI Research Internship</h5>
                            <p class="card-text"><small class="text-muted">Korea Institute of Science and Technology (KIST) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                              Oct 2021 ~ Aug 2022</small></p>
                              <p class="card-text">Supervised by <a href="https://scholar.google.com/citations?user=E6emHhkAAAAJ&hl=en">Dr. (Prof.) Suhyun Kim</a>, 
                                In KDST (KIST Data Science Team), I researched combining Knowledge Distillation and Network Inversion for Network Pruning.
                              </p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>


                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 224px">
                                <a href="https://saige.ai/"><img src="assets/saige_research_logo.jpeg" class="img-fluid" style="width: 60%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">AI Research Internship</h5>
                            <p class="card-text"><small class="text-muted">Saige Research Inc. &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                                Feb 2021 - Aug 2021</small></p>
                              <p class="card-text">Supervised by <a href="https://scholar.google.com/citations?user=u-h3PJIAAAAJ&hl=en">Dr. (Prof.) Frank Chongwoo Park</a>, 
                                Engaged in pattern recognition and Optical Character Recognition (OCR) research and 
                                customized various supervised OCR models with multifaceted experiments. 
                              </p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>


                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 224px">
                                <a href="https://www.linkedin.com/company/psx-seoul/?originalSubdomain=kr"><img src="assets/psx_logo.jpg" class="img-fluid" style="width: 60%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">Software Engineer Internship</h5>
                            <p class="card-text"><small class="text-muted">PSX Inc. &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                                Aug 2020 - Feb 2021</small></p>
                              <p class="card-text">
                                Developed services for trading unlisted stocks, including web development using Django and hybrid app development with React-Native.
                              </p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>
                
                <div class="col">
                    <div class="card experience-card mb-1">
                      <div class="row g-0">
                        <div class="col-5">
                            <div class="col d-flex align-items-center justify-content-center text-center" style="align-items: center; height: 224px">
                                <a href="https://en.snu.ac.kr/"><img src="assets/snu_logo.png" class="img-fluid" style="width: 60%"></a>
                            </div>
                        </div>
                        <div class="col-7">
                          <div class="card-body">
                            <h5 class="card-title">B.S. Student</h5>
                            <p class="card-text"><small class="text-muted">Seoul National Univeisity &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                                Mar 2018 - Feb 2023</small></p>
                              <p class="card-text">
                                Undergraduate Studies with a special focus on programming, simulation and mathmatics.
                              </p>
                          </div>
                        </div>
                      </div>
                    </div>
                </div>


            </div>
        </div>
        <br>
        <br>
        <br>
        <h1 class="gradiant-effect" id="connect"> GET IN TOUCH </h1>
        <br>
        <br>
        <div class="row">
    <div class="col-3"></div>
     <div class="col-2 text-center"><a href="mailto:lmcr136a@g.ucla.edu"><i class="fa-regular fa-envelope fa-2xl" data-tippy-content="E-Mail"></i></a></div>
     <div class="col-2 text-center"><a href="https://www.linkedin.com/in/steamhyeon/"><i class="fa-brands fa-linkedin fa-2xl" data-tippy-content="LinkedIn"></i></a></div>
    <div class="col-2 text-center"><a href="https://github.com/lmcr136a"><i class="fa-brands fa-github fa-2xl" data-tippy-content="GitHub"></i></a></div>
    <div class="col-3"></div>
</div>
        <br><br>
        <br><br>

        <script src="https://unpkg.com/@popperjs/core@2/dist/umd/popper.min.js"></script>
        <script src="https://unpkg.com/tippy.js@6/dist/tippy-bundle.umd.js"></script>

        <script src="https://apps.elfsight.com/p/platform.js" defer></script>
        <div class="elfsight-app-4fd6d63f-c493-4a30-8558-af66a359e9ef" align="center"></div>

        <script>
            tippy('[data-tippy-content]', {
                arrow: false,
                inertia: true,
                animation: 'scale',
                theme: 'gradiant',
                placement: 'bottom',
            });
        </script>

    </div>
</body>

</html>